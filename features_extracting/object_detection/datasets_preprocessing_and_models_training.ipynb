{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d7c68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "import random\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Конфигурация\n",
    "DATASETS_DIR = \"folder_with_zip_datasets_text\"  # Папка с исходными датасетами (ZIP-архивами)\n",
    "OUTPUT_DIR = \"DATASASET_TRAINING_TEXT\"  # Папка для итогового датасета\n",
    "\n",
    "TRAIN_SAMPLES_PER_DATASET = 5000\n",
    "VALID_SAMPLES_PER_DATASET = 500\n",
    "TEST_SAMPLES_PER_DATASET = 500\n",
    "\n",
    "datasets_description = pd.read_excel('text_datasets_description.xlsx')\n",
    "datasets_description = datasets_description.dropna()\n",
    "\n",
    "def process_labels(labels_dir, dataset_path, dataset_name):\n",
    "    \"\"\"Обрабатывает файлы с метками, применяя файл datasets_description.xlsx\"\"\"\n",
    "    \n",
    "    global datasets_description\n",
    "    print(dataset_name)\n",
    "    target_datasets_description = datasets_description[datasets_description['Dataset'] == dataset_name].copy()\n",
    "    # print(target_datasets_description)\n",
    "    for label_file in Path(labels_dir).glob(\"*.txt\"):\n",
    "        with open(label_file, 'r+') as file:\n",
    "            #try:\n",
    "            content = file.read()\n",
    "            content = content.split('\\n')\n",
    "\n",
    "            new_content = []\n",
    "            for box in content:\n",
    "                splitted_box = box.split(' ')\n",
    "                # print('Before swap:', splitted_box)\n",
    "                try:\n",
    "                    splitted_box[0] = target_datasets_description[target_datasets_description['Class_Number_Init'] == int(splitted_box[0])]['Class_Number_Target'].astype(int).astype(str).values[0]\n",
    "                except:\n",
    "                    pass\n",
    "                # print('After swap:', splitted_box)\n",
    "                box = ' '.join(splitted_box)\n",
    "                new_content.append(box)\n",
    "\n",
    "            file.truncate(0)\n",
    "            file.seek(0)\n",
    "\n",
    "            for row in new_content:\n",
    "                file.write(row + '\\n')\n",
    "\n",
    "            file.close()\n",
    "#             except:\n",
    "#                 print('Filename:', file)\n",
    "#                 print('Error')\n",
    "#                 print('-'*15)\n",
    "                \n",
    "def copy_random_samples(source_dir, dest_dir, num_samples):\n",
    "    \"\"\"Копирует случайные изображения и соответствующие метки\"\"\"\n",
    "    source_images = list((source_dir / \"images\").glob(\"*\"))\n",
    "    if not source_images:\n",
    "        return\n",
    "    \n",
    "    # Выбираем случайные изображения (не более чем есть)\n",
    "    selected_images = random.sample(source_images, min(num_samples, len(source_images)))\n",
    "    \n",
    "    # Создаем папки назначения, если их нет\n",
    "    (dest_dir / \"images\").mkdir(parents=True, exist_ok=True)\n",
    "    (dest_dir / \"labels\").mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for img_path in selected_images:\n",
    "        # Копируем изображение\n",
    "        shutil.copy(img_path, dest_dir / \"images\" / img_path.name)\n",
    "        \n",
    "        # Копируем соответствующую метку\n",
    "        label_path = (source_dir / \"labels\" / img_path.with_suffix(\".txt\").name)\n",
    "        if label_path.exists():\n",
    "            shutil.copy(label_path, dest_dir / \"labels\" / label_path.name)\n",
    "            \n",
    "def process_dataset(zip_path, output_base, dataset_name):\n",
    "    \"\"\"Обрабатывает один датасет\"\"\"\n",
    "    # Создаем временную папку для распаковки\n",
    "    temp_dir = Path(\"temp_extract\")\n",
    "    temp_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Распаковываем архив\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(temp_dir)\n",
    "    \n",
    "    # Ищем папки train, valid, test\n",
    "    dataset_folders = {}\n",
    "    for folder in [\"train\", \"valid\", \"test\"]:\n",
    "        for possible_path in temp_dir.rglob(folder):\n",
    "            if possible_path.is_dir():\n",
    "                dataset_folders[folder] = possible_path\n",
    "                break\n",
    "    \n",
    "    # Обрабатываем метки и копируем данные\n",
    "    for folder_type, source_path in dataset_folders.items():\n",
    "        # Обрабатываем метки\n",
    "        labels_dir = source_path / \"labels\"\n",
    "        if labels_dir.exists():\n",
    "            process_labels(labels_dir, source_path, dataset_name)\n",
    "        \n",
    "        # Определяем сколько samples брать\n",
    "        if folder_type == \"train\":\n",
    "            num_samples = TRAIN_SAMPLES_PER_DATASET\n",
    "        elif folder_type == \"valid\":\n",
    "            num_samples = VALID_SAMPLES_PER_DATASET\n",
    "        else:  # test\n",
    "            num_samples = TEST_SAMPLES_PER_DATASET\n",
    "        \n",
    "        # Копируем samples\n",
    "        \n",
    "        if folder_type == 'valid' or folder_type == 'test':\n",
    "            dest_dir = output_base / 'valid'\n",
    "            copy_random_samples(source_path, dest_dir, num_samples)\n",
    "        else:\n",
    "            dest_dir = output_base / folder_type\n",
    "            copy_random_samples(source_path, dest_dir, num_samples)\n",
    "    \n",
    "    # Удаляем временную папку\n",
    "    shutil.rmtree(temp_dir)\n",
    "    \n",
    "def main():\n",
    "    # Создаем структуру итогового датасета\n",
    "    output_base = Path(OUTPUT_DIR)\n",
    "    for folder in [\"train\", \"valid\", \"test\"]:\n",
    "        (output_base / folder).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Обрабатываем все ZIP-архивы в папке с датасетами\n",
    "    datasets = list(Path(DATASETS_DIR).glob(\"*.zip\"))\n",
    "    for dataset in datasets:\n",
    "        print(f\"Processing {dataset.name}...\")\n",
    "        process_dataset(dataset, output_base, dataset.name.replace('.zip', ''))\n",
    "#     dataset = list(Path(DATASETS_DIR).glob(\"*.zip\"))[17]\n",
    "#     process_dataset(dataset, output_base, dataset.name.replace('.zip', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f48a78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing YOLOML_III.v1-yoloml_iii.yolov11.zip...\n",
      "YOLOML_III.v1-yoloml_iii.yolov11\n",
      "YOLOML_III.v1-yoloml_iii.yolov11\n",
      "YOLOML_III.v1-yoloml_iii.yolov11\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869424dc",
   "metadata": {},
   "source": [
    "# Models Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a03c4ab",
   "metadata": {},
   "source": [
    "## Model for Text Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0f3af9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "# Load a model\n",
    "model = YOLO(\"yolo11s.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90b5b4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.146  Python-3.9.21 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=0.7, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=custom_data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=training_3, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=7, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=text_recognition, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=text_recognition\\training_3, save_frames=False, save_json=False, save_period=50, save_txt=False, scale=0.5, seed=22, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=4, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=1\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    819795  ultralytics.nn.modules.head.Detect           [1, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,428,179 parameters, 9,428,163 gradients, 21.5 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 95.922.2 MB/s, size: 27.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Studying\\2nd Course 2024 and 2025\\project_odsv_v2\\features_extracting\\object_detection\\datasets\\cust\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=640 at 70.0% CUDA memory utilization.\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (NVIDIA GeForce RTX 3060) 12.00G total, 0.14G reserved, 0.11G allocated, 11.75G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9428179       21.55         0.849         20.87         227.6        (1, 3, 640, 640)                    list\n",
      "     9428179        43.1         1.191         28.84         120.9        (2, 3, 640, 640)                    list\n",
      "     9428179       86.19         1.747         49.68         117.2        (4, 3, 640, 640)                    list\n",
      "     9428179       172.4         2.840         67.37         107.2        (8, 3, 640, 640)                    list\n",
      "     9428179       344.8         4.933         95.13         142.8       (16, 3, 640, 640)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 27 for CUDA:0 8.18G/12.00G (68%) \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 101.926.5 MB/s, size: 24.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning D:\\Studying\\2nd Course 2024 and 2025\\project_odsv_v2\\features_extracting\\object_detection\\datasets\\cust\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.1 ms, read: 64.115.8 MB/s, size: 28.2 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning D:\\Studying\\2nd Course 2024 and 2025\\project_odsv_v2\\features_extracting\\object_detection\\datasets\\custom\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to text_recognition\\training_3\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.000421875), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mtext_recognition\\training_3\u001b[0m\n",
      "Starting training for 4 hours...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100       6.6G      1.952      2.681      1.552        122        640: 100%|██████████| 52/52 [00:19<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.537      0.777      0.607      0.274\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/558      6.61G        1.3     0.9693      1.163        118        640: 100%|██████████| 52/52 [00:18<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.161      0.816      0.156     0.0732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/593      6.62G      1.314     0.9666       1.18        117        640: 100%|██████████| 52/52 [00:17<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.412      0.391      0.319      0.142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/607      6.63G      1.336     0.9802      1.205        134        640: 100%|██████████| 52/52 [00:18<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.608      0.631      0.676      0.304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/613      6.65G      1.254     0.9065      1.139        136        640: 100%|██████████| 52/52 [00:18<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.494      0.597      0.533      0.245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/615      6.63G      1.193     0.8633      1.118        112        640: 100%|██████████| 52/52 [00:17<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.665      0.796      0.798      0.468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/620      6.62G      1.188     0.8268      1.096        135        640: 100%|██████████| 52/52 [00:18<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.849      0.904      0.931      0.582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/621      6.65G      1.142     0.8114      1.089         91        640: 100%|██████████| 52/52 [00:17<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.821      0.843      0.897      0.542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/625      6.62G      1.098     0.7716      1.062        116        640: 100%|██████████| 52/52 [00:17<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.795      0.848      0.887      0.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/629      6.62G      1.095     0.7463      1.062        129        640: 100%|██████████| 52/52 [00:17<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.873      0.901       0.94      0.634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/631      6.62G      1.088     0.7386      1.057        110        640: 100%|██████████| 52/52 [00:18<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.812      0.881      0.907      0.578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/631      6.62G      1.076     0.7343      1.055        123        640: 100%|██████████| 52/52 [00:17<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.687      0.803      0.757      0.403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/634      6.65G      1.066     0.7254      1.041        135        640: 100%|██████████| 52/52 [00:17<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.838      0.911      0.929      0.599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/636      6.66G      1.028     0.6941      1.037        103        640: 100%|██████████| 52/52 [00:17<00:00,  3.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.814      0.875      0.904      0.604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/637      6.66G      1.032     0.6999      1.034        105        640: 100%|██████████| 52/52 [00:18<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.904      0.913      0.957      0.662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/637      6.64G      1.019     0.6803      1.022        105        640: 100%|██████████| 52/52 [00:18<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.811      0.922      0.909      0.632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/635      6.66G      0.974     0.6615      1.009        112        640: 100%|██████████| 52/52 [00:19<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.913      0.933      0.965      0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/633      6.63G     0.9975      0.657      1.011        118        640: 100%|██████████| 52/52 [00:18<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.951      0.937      0.979      0.721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/632      6.61G     0.9883     0.6525      1.009         81        640: 100%|██████████| 52/52 [00:21<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.835      0.887      0.923      0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/626      6.63G      1.008     0.6639       1.02         96        640: 100%|██████████| 52/52 [00:21<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.909      0.922      0.961      0.671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/621      6.62G     0.9882     0.6314      1.019        120        640: 100%|██████████| 52/52 [00:18<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.904      0.922      0.962      0.696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/621      6.63G     0.9792     0.6458      1.008        108        640: 100%|██████████| 52/52 [00:20<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.908      0.933      0.968      0.713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/618      6.66G      0.989     0.6521      1.021        121        640: 100%|██████████| 52/52 [00:19<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.902      0.929      0.963      0.663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/618      6.62G     0.9514     0.6366       1.01        127        640: 100%|██████████| 52/52 [00:19<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.919      0.932      0.967      0.679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/616      6.62G     0.9558      0.644     0.9982        130        640: 100%|██████████| 52/52 [00:17<00:00,  2.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:03"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801      0.918      0.925      0.972      0.702\n",
      "\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 7 epochs. Best results observed at epoch 18, best model saved as best.pt.\n",
      "To update EarlyStopping(patience=7) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25 epochs completed in 0.162 hours.\n",
      "Optimizer stripped from text_recognition\\training_3\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from text_recognition\\training_3\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating text_recognition\\training_3\\weights\\best.pt...\n",
      "Ultralytics 8.3.146  Python-3.9.21 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce RTX 3060, 12288MiB)\n",
      "YOLO11s summary (fused): 100 layers, 9,413,187 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 12/12 [00:04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        601       1801       0.95      0.937      0.979      0.721\n",
      "Speed: 0.2ms preprocess, 3.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mtext_recognition\\training_3\u001b[0m\n",
      "CPU times: total: 10min 27s\n",
      "Wall time: 10min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train the model\n",
    "train_results = model.train(\n",
    "    data=\"custom_data.yaml\",  # path to dataset YAML\n",
    "    # epochs=30,  # number of training epochs\n",
    "    time=4,\n",
    "    imgsz=640,  # training image size\n",
    "    device=0,  # device to run on, i.e. device=0 or device=0,1,2,3 or device=cpu\n",
    "    project='text_recognition',\n",
    "    name='training_3',\n",
    "    exist_ok=True,\n",
    "    val=True,\n",
    "    batch=0.7,\n",
    "    save_period=50,\n",
    "    patience=7,\n",
    "    seed=22\n",
    "    # cache='disk'\n",
    "    # pretrained=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba74a96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING \n",
      "inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "Results saved to \u001b[1mtext_recognition\\training_1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "video_id = '7507994789435002134'\n",
    "results = model('../../parsing/formatted_videos/{}.mp4'.format(video_id), save=True, iou=0.1, vid_stride=10, show=False, conf=0.5, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
